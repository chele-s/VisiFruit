# ðŸ”„ CÃ³mo Cambiar entre YOLOv8 y RT-DETR

## âš¡ Cambio RÃ¡pido (Recomendado)

### Para usar **YOLOv8** (por defecto - RECOMENDADO)
```bash
# Windows PowerShell
$env:MODEL_TYPE="yolov8"
python ai_inference_server.py
```

### Para usar **RT-DETR**
```bash
# Windows PowerShell
$env:MODEL_TYPE="rtdetr"
$env:MODEL_PATH="weights/rtdetr_best.pt"
python ai_inference_server.py
```

---

## ðŸ“‹ MÃ©todo con Archivo .env (MÃ¡s Limpio)

### Paso 1: Crear archivo `.env`
Copia `.env.example` a `.env`:
```bash
copy .env.example .env
```

### Paso 2: Editar `.env`
Abre `.env` y cambia la lÃ­nea:

**Para YOLOv8:**
```env
MODEL_TYPE=yolov8
MODEL_PATH=weights/best.pt
```

**Para RT-DETR:**
```env
MODEL_TYPE=rtdetr
MODEL_PATH=weights/rtdetr_best.pt
```

### Paso 3: Ejecutar servidor
```bash
python ai_inference_server.py
```

El servidor leerÃ¡ automÃ¡ticamente el `.env`

---

## âœ… Verificar Modelo Activo

Al iniciar el servidor, verÃ¡s en los logs:

```
============================================================
ðŸŽ¯ CONFIGURACIÃ“N DEL SERVIDOR
   Arquitectura: YOLOv8          <-- Modelo activo
   Modelo: weights/best.pt
   Device: cuda
   FP16: True
============================================================
ðŸ”„ Cargando modelo YOLOv8 desde weights/best.pt
ðŸŽ® GPU detectada: NVIDIA GeForce RTX 3050 Ti Laptop GPU
âœ… Modelo YOLOv8 cargado y listo
```

---

## ðŸŽ¯ RecomendaciÃ³n para VisiFruit

**Usa YOLOv8** porque:
- âœ… 35-45 FPS (2-3x mÃ¡s rÃ¡pido que RT-DETR)
- âœ… Latencia ~25ms (ideal para banda transportadora)
- âœ… Menor consumo de GPU
- âœ… Ya tienes modelo entrenado

**RT-DETR solo si**:
- Necesitas >95% precisiÃ³n absoluta
- No te importa velocidad (12-18 FPS)
- Tienes GPU mÃ¡s potente

---

## ðŸ“š MÃ¡s InformaciÃ³n

Lee la guÃ­a completa: `Guias de uso/Guias importantes/MODELO_YOLOV8_VS_RTDETR.md`

---

**Nota**: Si no tienes un modelo RT-DETR entrenado, necesitas entrenarlo primero con tus datos de frutas antes de usarlo.
